# 一、计算机系统概述

## 1.操作系统基本概念

### （1）操作系统的特征

1. 并发

   ​		并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

   ​		操作系统通过引入进程和线程，使得程序能够并发运行。

2. 共享

   ​		共享是指系统中的资源可以被多个并发进程共同使用。

   ​		有两种共享方式：互斥共享和同时共享。

   ​		**互斥共享的资源称为临界资源**，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

3. 虚拟

   ​		**虚拟技术把一个物理实体转换为多个逻辑实体**。

   ​		主要有两种虚拟技术：**时分复用技术和空分复用技术**。

   ​		**多个进程能在同一个处理器上并发执行使用了时分复用技术**，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

   ​		**虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。**地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

4. 异步

   ​		**异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。**

### （2）操作系统的目标和功能

1. 操作系统作为计算机系统资源的管理者
   + 进程管理
   + 内存管理
   + 文件管理
   + 设备管理
2. 操作系统作为用户与计算机硬件系统之间的接口
   + 命令接口
   + 程序接口（由一组系统调用组成）
3. 操作系统用作扩充机器，我们通常把覆盖了软件的机器称为扩充机器或**虚拟机**。



## 2.系统调用

​		所谓系统调用，是指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的公共子程序。**应用程序可通过系统调用来请求获得操作系统内核的服务**。

​		如果一个进程在用户态需要使用内核态的功能，就**进行系统调用从而陷入内核**，由操作系统代为完成。

![image-20210315161818409](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315161818409.png)

## 3.中断分类

### （1）外中断

​		由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

​		**每一条指令结束时，CPU会例行检查是否有外中断信号。**

### （2）异常（也称内中断、例外或陷入）

​		由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

## 4.原语

​		原语具有以下特点：

1. 处于操作系统的最底层，是最接近硬件的部分；

2. 这些程序的运行具有原子性，其**操作只能一气呵成**；

3. 这些程序的运行时间都较短，而且调用频繁。

   一般把进程控制的程序段称为原语，原语在执行期间不允许中断，是一个不可分割的基本单位。

# 二、进程和线程

## 1.进程与线程

### （1）进程

​		**进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位**。

​		进程实体由程序段、相关数据段和进程控制块PCB组成。进程映像是静态的，进程是动态的。

​		所谓创建/撤销进程，都是针对进程实体中的PCB操作，**PCB是进程存在的唯一标志**。

### （2）线程与多线程模型

​		**线程是比进程更小的运行单位，是程序执行流的最小单位，是资源调度的独立单位。**

​		一个进程中可以有多个线程，它们**共享进程资源**。

![image-20210315165739027](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315165739027.png)

### （3）区别

+ 拥有资源

  ​		进程是资源分配的基本单位，但是线程不拥有资源（除运行中必不可少的资源），但线程可与同属一个进程的其他线程共享进程所拥有的全部资源。

+ 调度

  ​		线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换；从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

+ 系统开销

  ​		由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及**当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容**，开销很小。

+ 通信方面

  ​	线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助进程间通信IPC。

PS：对于无线程系统，进程是资源分配、调度的独立单位。

## 2.进程状态的切换

![image-20210315170405169](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315170405169.png)

+ 就绪态：进程获得了除处理机以外的一切所需资源，一旦得到处理机便可立即运行。

+ 运行态：在单处理机环境下，每个时刻最多只有一个进程处于运行态。

+ 阻塞态：进程正在等待某一事件（如等待某资源为可用或等待I/O完成）而暂停运行。此时即使处理机空闲，该进程也不能运行。

+ 创建态：进程正在被创建，尚未转到就绪态。

+ 结束态：进程需要结束运行时，系统首先必须置该进程为结束态，然后再进一步处理资源  

  ​               释放和回收等工作。

## 3.进程的通信

​		进程同步与进程通信容易混淆，他们的区别在于：

+ 进程同步：控制多个进程按一定顺序执行；
+ 进程通信：进程间传输信息。

​        进程通信是一种手段，进程同步是一种目的。为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

​		各进程拥有独立的内存地址空间，为保证安全，**一个进程不能直接访问另一个进程。**

### （1）共享存储

​		在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行读/写操作实现进程之间的信息交换。

​		多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。

![image-20210315172220760](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315172220760.png)

+ 优点：无须复制，快捷，信息量大。
+ 缺点：
  + 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，**不方便网络通信**。
  + 在对共享空间进行读/写操作时，需要使用同步互斥工具（如P操作、V操作），对共享空间的读/写进行控制。**某进程要访问共享存储空间，则必须没有其他进程在该共享存储空间中进行写操作，否则访问行为就会被阻塞。**

### （2）消息传递

​		在消息传递系统中，进程间的数据交换是以格式化的信息为单位的。**若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。**进程通过系统提供的**发送消息和接收消息两个原语**进行数据交换。

1. 直接通信方式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队						   列上，接收进程从消息缓冲队列中取得消息。

   ![image-20210315172703573](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315172703573.png)

2. 间接通信方式：发送进程把消息发送到某个中间实体，接收进程从中间取得消息。相应的 						   通信系统称为电子邮件系统。

- 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便。
- 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合.

### （3）管道通信

​		所谓管道，是指用于连接一个读写进程和一个写进程以实现他们之间的通信的一个共享文件，又名pipe文件。管道的中间介质是文件。

​		为了协调双方的通信，管道机制必须提供以下三方面的协调能力：**互斥、同步和确定对方的存在。**

![image-20210315173357705](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315173357705.png)

​		管道可以理解为共享存储的优化和发展，存储空间进化为缓冲区。缓冲区没写满时不允许读；没读空时不允许写。

+ 优点：简单方便。
+ 缺点：
  + **管道只能采用半双工通信，若想实现双向同时通信，则需要设置两个管道。**
  + 只能在父子进程或兄弟进程之间使用。
  + 从管道读数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据。
  + 缓冲区有限。

### （4）FIFO

​		也称为命名管道，去除了管道只能在父子进程中使用的限制。

​		FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

![image-20210315174424946](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315174424946.png)

+ 优点：可以实现任意关系的进程间通信。
+ 缺点：
  + 长期存于系统中，使用不当容易出错。
  + 缓冲区有限。

### （5）信号量

​		它是一个计数器，可以用来控制多个线程对共享资源的访问。

+ 优点：可以同步进程。
+ 缺点：信号量有限。

### （6）信号

​		一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

### （7）套接字

​		与其它通信机制不同的是，它可用于不同机器间的进程通信。

+ 优点：
  + 传输数据为字节级，传输数据可自定义，数据量小效率高。
  + 传输数据时间短，性能高。
  + 适合于客户端和服务器端之间信息实时交互。
  + 可以加密,数据安全性强。
+ 缺点：需对传输的数据进行解析，转化成应用级的数据。

## 4.线程的通信

​		**线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制.**

### （1）锁机制

+ 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。

+ 读写锁：允许多个线程同时读共享数据，而**对写操作是互斥的**。

+ 自旋锁：与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠    

  ​               状态；而自旋锁则循环检测保持者是否已经释放锁。

+ 条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。**对条件的测试是在**

  ​			       **互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。**

### （2）信号量机制

+ 无名线程信号量
+ 命名线程信号量

### （3）信号机制

​		类似进程间的信号处理。

### （4）屏障

​		屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

## 5.进程调度算法

### （1）批处理系统

​		批处理系统没有太多的用户操作，在该系统中，调度算法**目标是保证吞吐量和周转时间**（从提交到终止的时间），**并没有考虑到响应时间，也不区分任务的紧急程度，交互性很糟糕。**

1. 先来先服务调度算法**First-Come First-Serverd（FCFS）**

​		**非抢占式的调度算法**，按照请求的顺序进行调度。

​		有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

   2.短作业优先调度算法**Shortest Job firs（SJF）**

​		**非抢占式的调度算法**，按估计运行时间最短的顺序进行调度。

​		长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

   3.最短剩余时间优先调度算法**Shortest Remaining Time Next（SRTN）**

​		**最短作业优先的抢占式版本**，按剩余运行时间的顺序进行调度。

​		当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

   4.高响应比优先调度算法**Highest Response Ratio Next（HRRN）**

​		**非抢占式的算法**，在每次调度时先计算各个作业/进程的响应比，选择响应比最高的作业/进程为其服务。

​															$响应比=\frac{等待时间+要求服务时间}{要求服务时间}$

![image-20210315224722192](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315224722192.png)

### （2）交互式系统

​		交互式系统有大量的用户交互操作，**在该系统中调度算法的目标是快速地相应。**

   1.时间片轮转调度算法**Round-Robin（RR）**

​		**抢占式的调度算法。**

​		将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。**当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。**

​		时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

   2.优先级调度算法

​		**抢占式与非抢占式均有的调度算法。**

​		为每个进程分配一个优先级，按优先级进行调度。

​		为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

   3.多级反馈队列调度算法

​		**抢占式的调度算法。**

​		一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

​		多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

​		每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

​		**可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。**

![image-20210315230727511](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315230727511.png)

![image-20210315230746408](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210315230746408.png)

### （3）实时系统

​		实时系统要求一个请求在一个确定时间内得到响应。

​		分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 6.进程同步

### （1）临界区

​		我们将一次仅允许一个进程使用的资源称为林计入资源。对临界资源的访问必须互斥进行。为了保证临界资源的正确使用，可以把临界资源的访问过程分成4个部分：

+ 进入区。为了进入临界区使用临界资源， 在进入区要检查可否进入临界区。

+ 临界区。**进程中访问临界资源的那段代码。**

+ 退出区。将正在访问临界区的标志清除。

+ 剩余区。代码中的剩余部分。

  ```C
  do{
  	entry section;    //进入区
  	critical section; //临界区
  	exit section;     //退出区
  	remainder section;//剩余区
  }
  ```

### （2）同步与互斥

+ 同步：同步也称直接制约关系，**使得进程有一定的先后执行关系**。

+ 互斥：互斥也称间接制约关系，多个进程在同一时刻只有一个进程能进入临界区。

  ​	为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

1. 空闲让进。
2. 忙则等待。
3. 有限等待。
4. 让权等待（进程不能进入临界区时，应立即释放处理器，防止进程忙等待。）。

### （3）信号量

​		信号量是一个整型变量，可用来解决同步与互斥问题。它只能被两个标准的原语wait(S)和signal(S)访问，也可记为“P操作”和“V操作”。**原语功能的不可中断性在单处理机上可由软件通过屏蔽中断方式实现。**

​		wait和signal操作可描述为：

```C
wait(S){//相当于进入区
	while(S<=0);
	S=S-1;
}
signal(S){//相当于退出区
	S=S+1;
}
```

​		wait操作中，只要S<=0，就会不断地进行测试。因此，**该机制并未遵循“让权等待”的准则，而是是进程处于“忙等状态”。**

​		若信号量的取值只能为0或者1，那么就成为了**互斥量（Mutex）**，0表示临界区已经加锁，1表示临界区解锁。

### （4）生产者-消费者问题

​		使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

```C
semaphore mutex = 1;//临界区互斥信号量
semaphore empty = N;//空闲缓冲区
semaphore full = 0;//缓冲区初始化为空

void producer() {
    while(1) {
        int item = produce_item();//生产数据
        P(empty);//获取空缓冲区单元
        P(mutex);//进入临界区
        insert_item(item);//将数据放入缓冲区
        V(mutex);//离开临界区，释放互斥信号量
        V(full);//满缓冲区数加1
    }
}

void consumer() {
    while(1) {
        P(full);//获取满缓冲区单元
        P(mutex);//进入临界区
        int item = remove_item();//从缓冲区中取出数据
        V(mutex);//离开临界区，释放互斥信号量
        V(empty);//空缓冲区数加1
        consume_item(item);//消费数据
    }
}

```

### （5）管程

​		在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作给系统管理带来了麻烦，于是产生了新的进程同步工具——管程。

```C
monitor Demo{//1.定义一个名为“Demo”的管程
    //2.定义共享数据结构，对应系统中的某种共享资源
    共享数据结构S;
    //4.对共享数据结构初始化的语句
    init_code(){
        S=5;//初始资源数等于5
    }
    //3.过程1：申请一个资源
    take_away(){
        对共享数据结构x的一系列处理;
        S--;//可用资源数-1
        ...
    }
    //3.过程2：归还一个资源
    give_back(){
        对共享数据结构x的一系列处理;
        S++;//可用资源数+1
        ...
    }
}
```

​		管程有一个重要特性：**在一个时刻只能有一个进程使用管程。**进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。为此，将阻塞原因定义为 **条件变量condition**。相关的操作：**wait()** 和 **signal()**可用来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

```C
monitor Demo{
    共享数据结构S;
	condition x;
    init_code(){...}
    
    take_away(){
        if(S<=0) x.wait();//资源不够，在条件变量x上阻塞等待
        资源足够，分配资源，做一系列相应处理;
    }
    
    give_back(){
        归还资源，做一系列相应处理;
        if(有进程等待)x.signal;//唤醒一个阻塞进程
    }
}
```

​		条件变量和信号量的比较：

+ 相似点：condition的wait/signal操作类似信号量的P/V操作,可以实现进程的阻塞/唤

  ​			    醒。

+ 不同点：condition“没有值”，仅实现了“排队等待”功能；而信号量是“有值”的，**信号量**

  ​				**的值反映了剩余资源数，在管程中，剩余资源数由共享数据结构记录。**

# 三、死锁

## 1.必要条件

1. 互斥：在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。

2. 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程主动                           

   释放。

3. 请求并保持：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其

   他进程占用，此时请求进程被阻塞，但对自己已获得的资源保持不放。

4. 循环等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

![image-20210316182537764](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316182537764.png)

## 2.处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

## 3.鸵鸟策略

​		把头埋在沙子里，假装根本没发生问题。

​		因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

​		当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

​		大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

## 4.死锁检测与死锁恢复

​		即不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

### （1）每种类型一个资源的死锁检测

![image-20210316192306547](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316192306547.png)

​		上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

​		图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

​		**每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。**

​		**死锁定理**：S为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的。

### （2）每种类型多个资源的死锁检测

![image-20210316192521798](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316192521798.png)

​		上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

​		进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

​		算法总结如下：

​		**每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。**

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

### （3）死锁恢复

- 资源剥夺法：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。
- 撤销进程法：强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。
- 进程回退法：让一个（或多个）进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺。

## 5.死锁预防

​		即在程序运行之前预防发生死锁。

### （1）破坏互斥条件

​		**SPOOLing技术（假脱机技术）。**

​		假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

### （2）破坏不可抢占条件

​		当一个已保持了某些不可剥夺资源的进程请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。

### （3）破坏请求并保持条件

​		采用预先静态分配法，**即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。**

### （4）破坏循环等待条件

​		为了破坏循环等待条件，可采用顺序资源分配法，即给资源统一编号，进程只能按编号顺序来请求资源。

## 6.死锁避免

​		在程序运行时避免发生死锁。

### （1）系统安全状态

​		避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配的安全性。若此次分配不会导致系统进入不安全状态，则允许分配；否则让进城等待。

​		![image-20210316194919837](C:\Users\Ursnus\AppData\Roaming\Typora\typora-user-images\image-20210316194919837.png)

​		图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

​		所谓安全状态，是指系统能按某种进程推进程序$(P_1,P_2,...,P_n)$为每个进程$P_i$分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可以按序完成。此时称$P_1,P_2,...,P_n$为安全序列。**若系统无法找到一个安全序列，则称系统处于不安全状态。**

​		**并非所有的不安全状态都是死锁状态。死锁状态是不安全状态的真子集。**

### （2）安全性算法与银行家算法

​		![02B610EC9E7649FDEAD7ED33C03778EA](F:\QQ\787551776\FileRecv\MobileFile\02B610EC9E7649FDEAD7ED33C03778EA.png)

![image-20210316201305842](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316201305842.png)

![image-20210316201316048](C:\Users\Ursnus\AppData\Roaming\Typora\typora-user-images\image-20210316201316048.png)

![image-20210316201323539](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316201323539.png)

# 四、内存管理

## 1.虚拟内存

### （1）虚拟内存基本概念

​		虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

​		为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。**当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。**

​		从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

### （2）局部性原理

​		快表、页高速缓存及虚拟内存技术从广义上讲，都属于高速缓存技术，该技术所依赖的原理就是局部性原理。

- 时间局部性。程序中的某条指令一旦执行，不久后该指令可能再次执行；某数据被访问过，不久后该数据可能再次被访问。其产生的典型原因是程序中存在着大量的循环操作。
- 空间局部性。一旦程序访问了某个存储单元，不久后其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内。

​        **时间局部性通过将近来使用的指令和数据保存到高速缓冲存储器中，并使用高速缓存的层次结构实现。**

​		**空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。**

​		**虚拟内存技术实际上建立了“内存—外存”的两级存储器结构，利用局部性原理实现高速缓存。基于局部性原理，在程序装入时，将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。**

### （3）虚拟内存技术的实现

​		虚拟内存技术允许将一个作业分多次调入内存。采用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实现需要**建立在离散分配的内存管理方式的基础上。**

​		虚拟内存的实现有以下三种方式：

- 请求分页存储管理

- 请求分段存储管理

- 请求段页式存储管理

  不管哪种方式，一般都需要以下几方面的硬件支持：

- 一定容量的内存或外存

- 页表机制（或段表机制），作为主要的数据结构

- 中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断。

- 地址变换机构，**逻辑地址到物理地址的变换。**

## 2.分区

### （1）固定分区分配

​		固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区，如此循环。

​		固定分区分配在划分分区时有两种不同的方法：分区大小相等和分区大小不等。

​		这种分区方式存在两个问题：一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间；二是主存利用率低，**当程序小于固定分区大小时，也占用一个完整的内存分区空间，这样分区内部就存在空间浪费，这种现象称为内部碎片。**

### （2）动态分区分配

​		动态分区分配又称为可变分区分配，这种分区方法不预先划分内存，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此，系统中分区的大小和数目是可变的。![image-20210317185720542](C:\Users\Ursnus\AppData\Roaming\Typora\typora-user-images\image-20210317185720542.png)

​		动态分区在开始分配时是很好的，但之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片（图3.6中最后的4MB和中间的6MB，且随着进程的换入/换出，很可能会出现更多、更小的内存块），内存的利用率随之下降，这些小的内存块称为**外部碎片。**

​		克服外部碎片可以通过紧凑技术来解决，即操作系统不时地对进程进行移动和整理。但这需要动态重定位寄存器的支持，且相对费时。

## 3.分页系统地址映射

​		**固定分区会产生内部碎片，动态分区会产生外部碎片**，这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了**分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。**每个进程也已块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

​		虽然从方法上来看，分页类似于分区的固定分区技术，但不同在于：块的大小相对分区要小很多，并且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片。**每个进程平均只产生半个块大小的内部碎片（也称页内碎片）**。

​		内存管理单元管理着地址空间和物理内存的转换，其中的页表存储着页（程序地址空间）和页框（物理内存空间）的映射表。

​		页也可理解为进程中的块，页框是内存中的块，外存直接称为块。**进程在执行时需要申请主存空间，即要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。**

​		**一个虚拟地址分成两部分，一部分存储页面号，一部分存储偏移量。**

​		下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

![image-20210316203556261](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316203556261.png)

## 4.页面置换算法

​		进程运行时，若其访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时若内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。选择调出页面的算法就称为页面置换算法。

​		页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

​		好的页面置换算法应有较低的页面更换频率，也就是说，应将以后不会再访问或以后较长时间内不会再访问的页面先调出。

### （1）最佳置换算法OPT

​		最佳（Optimal，OPT）置换算法选择的被淘汰页面是以后永不使用的页面，或是在最长时间内不再被访问的页面，以便保证获得最低的缺页率。然而，由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。但可以用OPT算法来评价其他算法。

​		举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```
		7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### （2）最近最久未使用置换算法LRU

​		LRU（Least Recently Used）置换算法选择最近最长时间未访问过的页面予以淘汰。

​		为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

​		因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

​		LRU算法的性能较好，但需要寄存器和栈的硬件支持。**LRU是堆栈类的算法，FIFO算法基于队列实现。**

```
					4，7，0，7，1，0，1，2，1，2，6
```

![image-20210316211953422](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316211953422.png)

### （3）先进先出页面置换算法FIFO

​		优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面。

​		该算法会将那些经常被访问的页面换出，导致缺页率升高。

​		FIFO算法还会产生所分配的物理块数增大而页故障数不减反增的异常现象，也称为Belady异常。只有FIFO算法可能产生Belady异常。

### （4）时钟（CLOCK）置换算法（也称最近未用算法NRU）

​		LRU算法的性能接近于OPT算法，但实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。为此i，操作系统的设计者尝试了许多种算法，都是CLOCK算法的变体。因为算法要循环扫描缓冲区，像时钟的指针一样转动，因此成为CLOCK算法。

​		简单的CLOCK算法给每帧关联一个附加位，称为使用位。当某页首次装入内存时，将该帧的使用位设置为1；当该页随后再被访问到时，其使用位也被置为1.对于页替换算法，用于替换的候选帧集合可视为一个循环缓冲区，并有一个指针与之相关联。

​		**当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0;若在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换;若所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并停留在最初的位置上，替换该帧中的页。**由于该算法循环检查各页面的情况，因此称CLOCK算法，又称最近未用算法(Not Recently Used，NRU)。

​		CLOCK算法的性能比较接近LRU算法，而通过增加使用的位数目，可以使得CLOCK算法更加高效。**在使用位的基础上再增加一个修改位，则得到改进型CLOCK置换算法。**这样，每帧都处于以下4种情况之一:

- 最近未被访问，也未被修改（u=0，m=0）
- 最近被访问，但未被修改（u=1，m=0）
- 最近未被访问，但被修改（u=0，m=1）
- 最近被访问，也被修改（u=1，m=1）

​		算法执行如下操作步骤：

1. 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。
   选择遇到的第一个帧(u= 0, m =0）用于替换。
2. 若第1步失败，则重新扫描，查找（u=0, m=1)的帧。选择遇到的第一个这样的帧用
   于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0.
3. 若第2步失败，则指针将回到它的最初位置，且集合中所有帧的使用位均为0。重复第
   1步，并且若有必要，重复第2步，以便可以找到供替换的帧。

​		**改进型CLOCK 算法优于简单CLOCK算法的地方在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，所以这样做会节省时间。**

​		假设系统给某进程分配了5个页框,刚开始,进程依次访问1,3,4,2,5号页面，系统会将这些页面连成一个循环队列，刚开始扫描指针指向第一个被访问的页面(即1号页)，如图3.26所示。

​		图3.26中，小括号内的数字就是使用位。接下来，若进程请求访问6号页面，则由于此时分配给进程的5个页框都被使用，因此必须选择一个页面置换出去。按照CLOCK置换算法的规则,在第一轮扫描中，指针扫过的页面的使用位应置为0。第一轮扫描的过程如图3.27所示。

![image-20210316214803693](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316214803693.png)



![image-20210316214936012](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316214936012.png)

第一轮扫描中，未找到使用位为0的页面，因此需要进行第二轮扫描。第二轮扫描中，1号页面的使用位为0，因此将1号页面换出，将6号页面换入，将6号页的访问位设置为1，并将扫描指针后移（若下次需要换出页面，则从3号页面开始扫描)，如图3.28所示。

![image-20210316215047326](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210316215047326.png)

​		注意一个小细节:假设1号页面原先占有的是x号物理块（页框)，则6号页面换入内存后也放在x号物理块中。



## 5.分段

​		分页管理方式是从计算机的角度考虑设计的，目的是提高内存的利用率，提升计算机的性能。分段管理方式的提出则考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。

​		虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

​		下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。![image-20210317195543556](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210317195543556.png)

​		分段的做法是把每个表分成段（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的），一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

## 6.分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：**分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护**。

## 7.段页式

​		程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

# 五、设备管理

## 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

### 1. 先来先服务

> FCFS, First Come First Served

​		按照磁盘请求的顺序进行调度。

​		优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

### 2. 最短寻道时间优先

> SSTF, Shortest Seek Time First

​		优先调度与当前磁头所在磁道距离最近的磁道。

​		虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

[![img](https://camo.githubusercontent.com/4aaee136900eb1ece1352fa6ca5b92f37e59801a6fcd0a2345afa73ca44fd5b0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67)](https://camo.githubusercontent.com/4aaee136900eb1ece1352fa6ca5b92f37e59801a6fcd0a2345afa73ca44fd5b0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67)



### 3. 电梯算法

> SCAN

​		电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

​		电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

​		因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

[![img](https://camo.githubusercontent.com/e4956eee145c33a868e367fe6a32eb40465503a4e6a31755ca4fe5a4a83d4019/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373163653038662d633132342d343735662d623439302d6265343466656463366432652e706e67)](https://camo.githubusercontent.com/e4956eee145c33a868e367fe6a32eb40465503a4e6a31755ca4fe5a4a83d4019/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373163653038662d633132342d343735662d623439302d6265343466656463366432652e706e67)

# 六、链接装载库

## 1.内存、栈、堆

​		一般应用程序内存空间有如下区域：

- **栈：由操作系统自动分配释放，存放函数的参数值、局部变量等的值，用于维护函数调用的上下文**
- **堆：一般由程序员分配释放，若程序员不释放，程序结束时可能由操作系统回收，用来容纳应用程序动态分配的内存区域**
- 可执行文件映像：**存储着可执行文件在内存中的映像**，由装载器装载是**将可执行文件的内存读取或映射到这里**
- 保留区：保留区并不是一个单一的内存区域，而是对**内存中受到保护而禁止访问的内存区域的总称**，如通常 C 语言讲无效指针赋值为 0（NULL），因此 0 地址正常情况下不可能有效的访问数据

### （1）栈

​		栈保存了一个函数调用所需要的维护信息，常被称为堆栈帧（Stack Frame）或活动记录（Activate Record），一般包含以下几方面：

- 函数的返回地址和参数
- 临时变量：包括函数的非静态局部变量以及编译器自动生成的其他临时变量
- 保存上下文：包括函数调用前后需要保持不变的寄存器

### （2）堆

堆分配算法：

- 空闲链表（Free List）
- 位图（Bitmap）
- 对象池

### （3）“段错误（segment fault）” 或 “非法操作，该内存地址不能 read/write”

​		典型的非法指针解引用造成的错误。当指针指向一个不允许读写的内存地址，而程序却试图利用指针来读或写该地址时，会出现这个错误。

普遍原因：

- 将指针初始化为 NULL，之后没有给它一个合理的值就开始使用指针
- 没用初始化栈中的指针，指针的值一般会是随机数，之后就直接开始使用指针

## 2.各平台文件格式

| 平台       | 可执行文件 | 目标文件 | 动态库/共享对象       | 静态库       |
| ---------- | ---------- | -------- | --------------------- | ------------ |
| Windows    | exe        | obj      | dll                   | lib          |
| Unix/Linux | ELF、out   | o        | so                    | a            |
| Mac        | Mach-O     | o        | dylib、tbd、framework | a、framework |

## 3.编译系统



​		以下是一个hello.c程序：

```C
#include <stdio.h>

int main()
{
    printf("hello, world\n");
    return 0;
}
```

​		在Unix系统上，由编译器把源文件转换为目标文件

```shell
gcc -o hello hello.c
```

​		这个过程大致如下：

![img](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62333936643732362d623735662d346133322d383961322d3033613762366531396636662e6a7067)

- 预处理阶段：处理以#开头的预编译命令，生成`.i`或`.ii`文件；
- 编译阶段：翻译成汇编文件（编译器进行词法分析、语法分析、语义分析、中间代码生成、目标代码生成、优化，生成 `.s` 文件）；
- 汇编阶段：将汇编文件翻译成可重定位目标文件（汇编器把汇编码翻译成机器码，生成 `.o` 文件）；
- 链接阶段：将可重定位目标文件`.o`文件和printf.o等单独编译好的目标文件进行合并，得到最终的可执行目标文件`prog`文件（连接器进行地址和空间分配、符号决议、重定位，生成 `.out` 文件）。

## 4.链接的接口——符号

### （1）符号与符号表

​		在链接中，目标文件之间相互拼合实际上是目标文件之间对地址的引用，即对函数和变量的地址的引用。所谓的符号（Symbol），就是程序中的**函数、全局变量以及静态变量**，函数名或变量名就是符号名（Symbol Name）。

​		每个可重定位目标文件都有一个`.symtab`节，该节是一个符号表，包含该模块m定义和引用的符号的信息。

如下符号表（Symbol Table）：

| Symbol（符号名） | Symbol Value （地址） |
| ---------------- | --------------------- |
| main             | 0x100                 |
| Add              | 0x123                 |
| ...              | ...                   |

### （2）符号解析

​		三种符号链接器符号：

- 全局符号：由模块m定义并能被其他模块引用，如非静态的C函数和非静态的全局变量.

- 外部符号：**模块m引用的在其他模块中定义的全局符号.**

- 局部符号：只能由模块m自己引用的符号，如**静态的C函数和全局变量.**

  注意：局部变量不是局部符号

  静态变量和局部变量的区别：

- 存储位置不同：**局部变量存储在栈上，静态变量存储在`.bss`或`.data`节.**

- 作用域不同：**局部变量的作用域是函数或循环体，静态变量由于存放在内存静态区**，所以即使函数执行结束它的值也不会销毁，下次调用函数时仍然能用到这个值.

### （3）重定位

​		重定位就是将输入的多个可重定位目标文件合并为一个可执行目标文件。重定位由两步组成：

- 重定位节和符号定义：合并相同类型的节
- 重定位节中的符号引用：更新代码节和数据节中对符号的引用

## 5.静态链接

​		静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。**把每个函数单独放在一个文件中，编译为独立的目标模块，然后把这些模块封装成一个单独的静态库文件。**这样对某一个函数的改动只需编译该函数所在的文件即可，不需要重新编译整个源文件。

**链接器主要完成以下两个任务：**

- 符号解析
- 重定位



![image-20210318001219450](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210318001219450.png)

## 6.目标文件

​		编译器编译源代码后生成的文件叫做目标文件。目标文件从结构上讲，它是已经编译后的可执行文件格式，只是还没有经过链接的过程，其中可能有些符号或有些地址还没有被调整。

- 可执行目标文件`a.out`文件：可以直接在内存中执行；
- 可重定位目标文件`.o`文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
- 共享目标文件`.so`文件：这是一种**特殊的可重定位目标文件**，**可以在运行时被动态加载进内存并链接，在windows系统中又名DLL ；**

## 7.动态链接

​		静态库有以下两个问题：

- 如果静态库更新，程序员需要显式地将他们的程序与静态库重新链接。
- 几乎每个程序都会用到标准IO函数，如printf和scanf，而这些函数在每个进程中都有一份拷贝，浪费内存资源。

​		共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。**共享库被动态链接到可执行模块，内存中的一个共享库可以被多个进程使用，节省了内存空间。**

​		动态链接分为两种：

- 加载时动态链接：**将用户程序编译后所得到的一组目标模块，再装入内存时，采用边装入边链接的方式。**Linux中很常见，由动态链接器自动完成
- 运行时动态链接：**对某些目标模块的链接，是在程序执行中需要该目标模块时才进行的。**在Linux中通过调用dlopen完成

![image-20210318001356865](http://uranus-picture.oss-cn-beijing.aliyuncs.com/img/image-20210318001356865.png)